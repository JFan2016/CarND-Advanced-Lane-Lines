* Introduction
* Data

  #+BEGIN_SRC sh
  wget https://s3.amazonaws.com/udacity-sdc/advanced_lane_finding/signs_vehicles_xygrad.png
  #+END_SRC

  #+RESULTS:

  #+BEGIN_SRC python
  def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):
      # Calculate directional gradient
      # Apply threshold
      return grad_binary
  #+END_SRC
   
  #+BEGIN_SRC python
  def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):
      # Calculate gradient magnitude
      # Apply threshold
      return mag_binary
  #+END_SRC
   
  #+BEGIN_SRC python
  def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):
      # Calculate gradient direction
      # Apply threshold
      return dir_binary
  #+END_SRC
   
  #+BEGIN_SRC python
  # Choose a Sobel kernel size
  ksize = 3 # Choose a larger odd number to smooth gradient measurements
   
  # Apply each of the thresholding functions
  gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(0, 255))
  grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(0, 255))
  mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(0, 255))
  dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0, np.pi/2))  

  combined = np.zeros_like(dir_binary)
  combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1
  #+END_SRC

* Steps
  1. Camera Calibration
  2. Distortion Correction
  3. Color & Gradient Threshold
  4. Perspective Transform

* Histogram

  #+BEGIN_SRC python
  histogram = np.sum(img[img.shape[0]/2:,:], axis=0)
  plt.plot(histogram)  
  #+END_SRC

* Curvature

  #+BEGIN_SRC python
  import numpy as np
  # Generate some fake data to represent lane-line pixels
  yvals = np.linspace(0, 100, num=101)*7.2  # to cover same y-range as image
  leftx = np.array([200 + (elem**2)*4e-4 + np.random.randint(-50, high=51) 
                                for idx, elem in enumerate(yvals)])
  leftx = leftx[::-1]  # Reverse to match top-to-bottom in y
  rightx = np.array([900 + (elem**2)*4e-4 + np.random.randint(-50, high=51) 
                                  for idx, elem in enumerate(yvals)])
  rightx = rightx[::-1]  # Reverse to match top-to-bottom in y
   
  # Fit a second order polynomial to each fake lane line
  left_fit = np.polyfit(yvals, leftx, 2)
  left_fitx = left_fit[0]*yvals**2 + left_fit[1]*yvals + left_fit[2]
  right_fit = np.polyfit(yvals, rightx, 2)
  right_fitx = right_fit[0]*yvals**2 + right_fit[1]*yvals + right_fit[2]
   
  # Plot up the fake data
  plt.plot(leftx, yvals, 'o', color='red')
  plt.plot(rightx, yvals, 'o', color='blue')
  plt.xlim(0, 1280)
  plt.ylim(0, 720)
  plt.plot(left_fitx, yvals, color='green', linewidth=3)
  plt.plot(right_fitx, yvals, color='green', linewidth=3)
  plt.gca().invert_yaxis() # to visualize as we do the images  
  #+END_SRC

  #+BEGIN_SRC python
  # Define y-value where we want radius of curvature
  # I'll choose the maximum y-value, corresponding to the bottom of the image
  y_eval = np.max(yvals)
  left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) \
                               /np.absolute(2*left_fit[0])
  right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) \
                                  /np.absolute(2*right_fit[0])
  print(left_curverad, right_curverad)
  # Example values: 1163.9    1213.7  
  #+END_SRC

  #+BEGIN_SRC python
  # Define conversions in x and y from pixels space to meters
  ym_per_pix = 30/720 # meters per pixel in y dimension
  xm_per_pix = 3.7/700 # meteres per pixel in x dimension
   
  left_fit_cr = np.polyfit(yvals*ym_per_pix, leftx*xm_per_pix, 2)
  right_fit_cr = np.polyfit(yvals*ym_per_pix, rightx*xm_per_pix, 2)
  left_curverad = ((1 + (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) \
                               /np.absolute(2*left_fit_cr[0])
  right_curverad = ((1 + (2*right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) \
                                  /np.absolute(2*right_fit_cr[0])
  # Now our radius of curvature is in meters
  print(left_curverad, 'm', right_curverad, 'm')
  # Example values: 3380.7 m    3189.3 m  
  #+END_SRC

* Additional Techniques
  1. Region Masking
  2. Edge Detection
  3. Color Selection
  4. Hough Transforms

* Tips
  1. Try allowing for a complex region shape defined by the position
     of the lane lines in your last frame of video.
  2. For edge detection, compare the result of cv2.Canny() with a
     combined gradient magnitude and direction threshold.
  3. For color selection, look at alternative color spaces and
     selections.
  4. Look up fitting curves with Hough, rather than just straight
     lines.

* Tracking Recent Measurements

  #+BEGIN_SRC python
  # Define a class to receive the characteristics of each line detection
  class Line():
      def __init__(self):
          # was the line detected in the last iteration?
          self.detected = False  
          # x values of the last n fits of the line
          self.recent_xfitted = [] 
          #average x values of the fitted line over the last n iterations
          self.bestx = None     
          #polynomial coefficients averaged over the last n iterations
          self.best_fit = None  
          #polynomial coefficients for the most recent fit
          self.current_fit = [np.array([False])]  
          #radius of curvature of the line in some units
          self.radius_of_curvature = None 
          #distance in meters of vehicle center from the line
          self.line_base_pos = None 
          #difference in fit coefficients between last and new fits
          self.diffs = np.array([0,0,0], dtype='float') 
          #x values for detected line pixels
          self.allx = None  
          #y values for detected line pixels
          self.ally = None  
  #+END_SRC

* Testing
  Confirm that your detected lane lines are real.
*** Checking that they have similar curvature
*** Checking that they are separated by approximately the right distance horizontally
*** Checking that they are roughly parallel

* More Tips
*** After determining you found the lines, where to look in the next frame.
    1. Search for the new line within +/- some margin around the old
       line center.
    2. Then check that your new line detections makes sense, i.e.,
       expected curvature, separation, and parallel.
*** If you lose track of the lines
    1. If your sanity checks reveal that the lane lines you've
       detected are problematic for some reason, you can simply assume
       it was a bad or difficult frame of video, retain the previous
       positions from the frame prior and step to the next frame to
       search again.
    2. If you lose the lines for several frames in a row, you should
       probably go back to the blind search method using a histogram
       and sliding window, or other method, to re-establish your
       measurement.
*** Smoothing your measurement
    1. Each time you get a new high-confidence measurement, you can
       append it to the list of recent measurements.
    2. Then take an average over n past measurements to obtain the
       lane position you want to draw onto the image.
*** Drawing the lines back down onto the road
    1. Get a warped binary image called warped.
    2. Get arrays called yvals, left_fitx and right_fitx, which
       represent the x and y pixel values of the lines.
    3. Project those lines onto the original image.

       #+BEGIN_SRC python
       # Create an image to draw the lines on
       warp_zero = np.zeros_like(warped).astype(np.uint8)
       color_warp = np.dstack((warp_zero, warp_zero, warp_zero))
        
       # Recast the x and y points into usable format for cv2.fillPoly()
       pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])
       pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])
       pts = np.hstack((pts_left, pts_right))
        
       # Draw the lane onto the warped blank image
       cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))
        
       # Warp the blank back to original image space using inverse perspective matrix (Minv)
       newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) 
       # Combine the result with the original image
       result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)
       plt.imshow(result)       
       #+END_SRC

* Project Details
*** Repository
    https://github.com/udacity/CarND-Advanced-Lane-Lines
*** Write-up Template
    https://github.com/udacity/CarND-Advanced-Lane-Lines/blob/master/writeup_template.md
*** Rubric
    https://review.udacity.com/#!/rubrics/571/view
*** Other Resources
    https://en.wikipedia.org/wiki/HSL_and_HSV
    http://www.intmath.com/applications-differentiation/8-radius-curvature.php
    http://onlinemanuals.txdot.gov/txdotmanuals/rdw/horizontal_alignment.htm#BGBHGEGC
*** Important Points
    1. Include a detailed description of the code used in each step
       (with line-number references and code snippets where necessary).
    2. Links to other supporting documents or external references.
    3. Include images in your writeup to demonstrate how your code
       works with examples.
    4. Be concise.
    5. Save example images from each stage of your pipeline to the
       output_images folder.
    6. Provide a description of what each image shows in your writeup
       for the project.
    7. Save your output video and include it with your submission.
